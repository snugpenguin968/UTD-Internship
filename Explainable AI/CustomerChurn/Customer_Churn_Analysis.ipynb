{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customer Churn Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMg5emIyCqYewMXcY/kR5Z/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Churn Analysis"
      ],
      "metadata": {
        "id": "WnYrfN2Kl8ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0EXmfDVlzjN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import sys\n",
        "if not sys.warnoptions:\n",
        "    import os, warnings\n",
        "    warnings.simplefilter(\"ignore\") \n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" \n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,KFold\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,VotingClassifier,BaggingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "pd.options.display.float_format = \"{:,.2f}\".format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"churn.csv\")"
      ],
      "metadata": {
        "id": "S1suR7rDl7Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "0pi2MmbOmIHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "UyHSXtFAmIyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "Na0MzO7nmKyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizations"
      ],
      "metadata": {
        "id": "ViRfaNv2mSwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,6)) \n",
        "sns.heatmap(df.corr(), annot = True, fmt = \".2f\", linewidths=0.5, ax=ax) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tk-appwumPNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g= sns.factorplot(x = \"Tenure\", y = \"Exited\", data = df, kind = \"bar\", size = 4)\n",
        "g.set_ylabels(\"Churn Probability\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KwmJWeq1mVdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a lower chance of exit in the mid Tenure range"
      ],
      "metadata": {
        "id": "zj8v0MKVmeKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g= sns.factorplot(x = \"Gender\", y = \"Exited\", data = df, kind = \"bar\", size = 5)\n",
        "g.set_ylabels(\"Churn Probability\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nYS92AoMmbPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Females have a higher chance of exiting"
      ],
      "metadata": {
        "id": "20hC8EgxmjCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g= sns.FacetGrid(df, col = \"Exited\")\n",
        "g.map(sns.distplot, \"Age\", bins = 25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NT4EWIeomiGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g= sns.FacetGrid(df, col = \"Exited\")\n",
        "g.map(sns.distplot, \"Balance\", bins = 25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lWPsS5eLmlvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g= sns.FacetGrid(df, col = \"Exited\")\n",
        "g.map(sns.distplot, \"EstimatedSalary\", bins = 25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aid6Y7DnmnRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g= sns.FacetGrid(df, col = \"Exited\")\n",
        "g.map(sns.distplot, \"CreditScore\", bins = 25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nQ4DWIjcmq6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "r9zpxyxNnLhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = df.drop(['RowNumber',\"Exited\"], axis=1)\n",
        "target = df[\"Exited\"]\n",
        "x_train, x_val, y_train, y_val = train_test_split(xs, target, test_size = 0.20, random_state = 0)\n",
        "\n",
        "val_ids = x_val['CustomerId']\n",
        "train_ids=x_train['CustomerId']\n",
        "\n",
        "x_train = x_train.drop(['CustomerId'], axis=1)\n",
        "x_val= x_val.drop(['CustomerId'], axis=1)\n",
        "\n",
        "df_train=df[df['CustomerId'].isin(train_ids)]\n",
        "df_val=df[df['CustomerId'].isin(val_ids)]"
      ],
      "metadata": {
        "id": "5-_I4FwSmsjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "FKoq1ysBmw3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [x_train,x_val]:\n",
        "    df[\"Gender\"]=df[\"Gender\"].map(lambda x: 0 if x=='Female' else 1)\n",
        "    df.drop(['Surname'], axis = 1, inplace=True)"
      ],
      "metadata": {
        "id": "CHPX-PiNm1al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val= [ pd.get_dummies(data, columns = ['Geography']) for data in [x_train,x_val]]"
      ],
      "metadata": {
        "id": "6qX82oI1nIvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "ZrY3GUe9nKx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.info()"
      ],
      "metadata": {
        "id": "Wx3Of8LBnPiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "zj4ktYYynY1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r=1309\n",
        "models = [LogisticRegression(random_state=r),GaussianNB(), KNeighborsClassifier(),\n",
        "          SVC(random_state=r,probability=True),BaggingClassifier(random_state=r),DecisionTreeClassifier(random_state=r),\n",
        "          RandomForestClassifier(random_state=r), GradientBoostingClassifier(random_state=r),\n",
        "          XGBClassifier(random_state=r), MLPClassifier(random_state=r)]\n",
        "names = [\"LogisticRegression\",\"GaussianNB\",\"KNN\",\"SVC\",\"Bagging\",\n",
        "             \"DecisionTree\",\"Random_Forest\",\"GBM\",\"XGBoost\",\"Art.Neural_Network\"]"
      ],
      "metadata": {
        "id": "3PkRW9ItnQrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Default model validation accuracies for the train data:', end = \"\\n\\n\")\n",
        "for name, model in zip(names, models):\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_val) \n",
        "    print(name,':',\"%.3f\" % accuracy_score(y_pred, y_val))"
      ],
      "metadata": {
        "id": "-ExtgNG0nSxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors=pd.concat([x_train,x_val])"
      ],
      "metadata": {
        "id": "uMgYXRnjndeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "print('10 fold Cross validation accuracy', end = \"\\n\\n\")\n",
        "for name, model in zip(names, models):\n",
        "    kfold = KFold(n_splits=10, random_state=1001,shuffle=True)\n",
        "    cv_results = cross_val_score(model, predictors, target, cv = kfold, scoring = \"accuracy\")\n",
        "    results.append(cv_results)\n",
        "    print(\"{}: {} ({})\".format(name, \"%.3f\" % cv_results.mean() ,\"%.3f\" %  cv_results.std()))"
      ],
      "metadata": {
        "id": "2rHg_pe6nimO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logreg_params= {\"C\":np.logspace(-1, 1, 10),\n",
        "                    \"penalty\": [\"l1\",\"l2\"], \"solver\":['lbfgs', 'liblinear', 'sag', 'saga'], \"max_iter\":[1000]}\n",
        "\n",
        "NB_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        "knn_params= {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n",
        "                 \"weights\": [\"uniform\",\"distance\"],\n",
        "                 \"metric\":[\"euclidean\",\"manhattan\"]}\n",
        "svc_params= {\"kernel\" : [\"rbf\"],\n",
        "                 \"gamma\": [0.001, 0.01, 0.1, 1, 5, 10 ,50 ,100],\n",
        "                 \"C\": [1,10,50,100,200,300,1000]}\n",
        "bag_params={\"n_estimators\":[50,120,300]}\n",
        "dtree_params = {\"min_samples_split\" : range(10,500,20),\n",
        "                \"max_depth\": range(1,20,2)}\n",
        "rf_params = {\"max_features\": [\"log2\",\"auto\",\"sqrt\"],\n",
        "                \"min_samples_split\":[2,3,5],\n",
        "                \"min_samples_leaf\":[1,3,5],\n",
        "                \"bootstrap\":[True,False],\n",
        "                \"n_estimators\":[50,100,150],\n",
        "                \"criterion\":[\"gini\",\"entropy\"]}\n",
        "gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n",
        "             \"n_estimators\": [100,500,100],\n",
        "             \"max_depth\": [3,5,10],\n",
        "             \"min_samples_split\": [2,5,10]}\n",
        "gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n",
        "             \"n_estimators\": [100,500,100],\n",
        "             \"max_depth\": [3,5,10],\n",
        "             \"min_samples_split\": [2,5,10]}\n",
        "\n",
        "xgb_params ={\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'subsample': [ 0.6, 0.8, 1.0],\n",
        "        'max_depth': [1,2,3,4],\n",
        "        'learning_rate': [0.1,0.2, 0.3, 0.4, 0.5],\n",
        "        \"min_samples_split\": [1,2,4,6]}\n",
        "\n",
        "mlpc_params = {\"alpha\": [0.1, 0.01, 0.02, 0.005, 0.0001,0.00001],\n",
        "              \"hidden_layer_sizes\": [(10,10,10),\n",
        "                                     (100,100,100),\n",
        "                                     (100,100),\n",
        "                                     (3,5), \n",
        "                                     (5, 3)],\n",
        "              \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\"max_iter\":[1000]}\n",
        "\n",
        "classifier_params = [logreg_params,NB_params,knn_params,svc_params,bag_params,dtree_params,rf_params,\n",
        "                     gbm_params, xgb_params,mlpc_params]  "
      ],
      "metadata": {
        "id": "iVeY36QHnkcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_result = {}\n",
        "best_estimators = {}\n",
        "for name, model,classifier_param in zip(names, models,classifier_params):\n",
        "      clf = GridSearchCV(model, param_grid=classifier_param, cv =10, scoring = \"accuracy\", n_jobs = -1,verbose = False)\n",
        "      clf.fit(x_train,y_train)\n",
        "      cv_result[name]=clf.best_score_\n",
        "      best_estimators[name]=clf.best_estimator_\n",
        "      print(name,'cross validation accuracy : %.3f'%cv_result[name])"
      ],
      "metadata": {
        "id": "hhmA4hVBn1Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies={}\n",
        "print('Validation accuracies', end = \"\\n\\n\")\n",
        "for name, model_tuned in zip(best_estimators.keys(),best_estimators.values()):\n",
        "    y_pred =  model_tuned.fit(x_train,y_train).predict(x_val)\n",
        "    accuracy=accuracy_score(y_pred, y_val)\n",
        "    print(name,':', \"%.3f\" %accuracy)\n",
        "    accuracies[name]=accuracy"
      ],
      "metadata": {
        "id": "NRz5m-Psn-Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=3\n",
        "accu=sorted(accuracies, reverse=True, key= lambda k:accuracies[k])[:n]\n",
        "firstn=[[k,v] for k,v in best_estimators.items() if k in accu]"
      ],
      "metadata": {
        "id": "9I0UtjNToBgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "votingC = VotingClassifier(estimators = firstn, voting = \"soft\", n_jobs = -1)\n",
        "votingC = votingC.fit(x_train, y_train)\n",
        "print(accuracy_score(votingC.predict(x_val),y_val))"
      ],
      "metadata": {
        "id": "bMM9yC6HoEQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A small improvement over FOLD-R++, but in the world of ML, such a difference can have a huge impact"
      ],
      "metadata": {
        "id": "yRC15D8NoWEr"
      }
    }
  ]
}